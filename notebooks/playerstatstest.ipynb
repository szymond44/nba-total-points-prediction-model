{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc3f02e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b686e301",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from data.api_fetcher import ApiFetcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9bc132ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = ApiFetcher(starting_year=2019, ending_year=2025)\n",
    "df_p = api.get_dataframe('playerstats', all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "826322f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_g = api.get_dataframe('leaguegamelog', all = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f2d2a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['season_year', 'player_id', 'player_name', 'nickname', 'team_id',\n",
      "       'team_abbreviation', 'team_name', 'game_id', 'game_date', 'matchup',\n",
      "       'wl', 'min', 'fgm', 'fga', 'fg_pct', 'fg3m', 'fg3a', 'fg3_pct', 'ftm',\n",
      "       'fta', 'ft_pct', 'oreb', 'dreb', 'reb', 'ast', 'tov', 'stl', 'blk',\n",
      "       'blka', 'pf', 'pfd', 'pts', 'plus_minus', 'nba_fantasy_pts', 'dd2',\n",
      "       'td3', 'wnba_fantasy_pts', 'gp_rank', 'w_rank', 'l_rank', 'w_pct_rank',\n",
      "       'min_rank', 'fgm_rank', 'fga_rank', 'fg_pct_rank', 'fg3m_rank',\n",
      "       'fg3a_rank', 'fg3_pct_rank', 'ftm_rank', 'fta_rank', 'ft_pct_rank',\n",
      "       'oreb_rank', 'dreb_rank', 'reb_rank', 'ast_rank', 'tov_rank',\n",
      "       'stl_rank', 'blk_rank', 'blka_rank', 'pf_rank', 'pfd_rank', 'pts_rank',\n",
      "       'plus_minus_rank', 'nba_fantasy_pts_rank', 'dd2_rank', 'td3_rank',\n",
      "       'wnba_fantasy_pts_rank', 'available_flag', 'min_sec', 'team_count',\n",
      "       'season', 'ts_pct', 'ast_to_ratio', 'pts_per_fga', 'reb_per_min',\n",
      "       'pts_ast_composite', 'usage_composite', 'fg3a_rate', 'fta_rate',\n",
      "       'is_win', 'is_home'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_p.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bee7821a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['game_id', 'date', 'home_team', 'away_team', 'home_season_id',\n",
      "       'home_team_id', 'home_team_abbreviation', 'home_wl', 'home_min',\n",
      "       'home_fgm', 'home_fga', 'home_fg_pct', 'home_fg3m', 'home_fg3a',\n",
      "       'home_fg3_pct', 'home_ftm', 'home_fta', 'home_ft_pct', 'home_oreb',\n",
      "       'home_dreb', 'home_reb', 'home_ast', 'home_stl', 'home_blk', 'home_tov',\n",
      "       'home_pf', 'home_pts', 'home_plus_minus', 'home_video_available',\n",
      "       'away_season_id', 'away_team_id', 'away_team_abbreviation', 'away_wl',\n",
      "       'away_min', 'away_fgm', 'away_fga', 'away_fg_pct', 'away_fg3m',\n",
      "       'away_fg3a', 'away_fg3_pct', 'away_ftm', 'away_fta', 'away_ft_pct',\n",
      "       'away_oreb', 'away_dreb', 'away_reb', 'away_ast', 'away_stl',\n",
      "       'away_blk', 'away_tov', 'away_pf', 'away_pts', 'away_plus_minus',\n",
      "       'away_video_available'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_g.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e883b26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data validation - checks for errors and inconsistencies\n",
    "Does NOT modify data, only reports issues\n",
    "Customized for your specific column structure\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def validate_games_dataframe(df_g):\n",
    "    \"\"\"\n",
    "    Check games dataframe for issues\n",
    "    \n",
    "    Args:\n",
    "        df_g: Games DataFrame (with your column structure)\n",
    "        \n",
    "    Returns:\n",
    "        dict: Validation results with issues found\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ” VALIDATING GAMES DATAFRAME\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    issues = []\n",
    "    warnings = []\n",
    "    \n",
    "    # Basic info\n",
    "    print(f\"\\nğŸ“Š Dataset Info:\")\n",
    "    print(f\"   Total games: {len(df_g)}\")\n",
    "    print(f\"   Date range: {df_g['date'].min()} to {df_g['date'].max()}\")\n",
    "    print(f\"   Unique teams: {df_g['home_team_id'].nunique()}\")\n",
    "    \n",
    "    # Check 1: Missing values\n",
    "    print(f\"\\nğŸ” Checking for missing values...\")\n",
    "    critical_cols = ['game_id', 'date', 'home_team_id', 'away_team_id', \n",
    "                     'home_pts', 'away_pts']\n",
    "    \n",
    "    missing_found = False\n",
    "    for col in critical_cols:\n",
    "        if col not in df_g.columns:\n",
    "            issues.append(f\"Missing column: {col}\")\n",
    "            missing_found = True\n",
    "        else:\n",
    "            missing = df_g[col].isna().sum()\n",
    "            if missing > 0:\n",
    "                issues.append(f\"{col}: {missing} missing values\")\n",
    "                missing_found = True\n",
    "                print(f\"   âŒ {col}: {missing} missing values\")\n",
    "    \n",
    "    if not missing_found:\n",
    "        print(\"   âœ… No missing values in critical columns\")\n",
    "    \n",
    "    # Check 2: Duplicate games\n",
    "    print(f\"\\nğŸ” Checking for duplicates...\")\n",
    "    duplicates = df_g['game_id'].duplicated().sum()\n",
    "    if duplicates > 0:\n",
    "        issues.append(f\"{duplicates} duplicate game_ids\")\n",
    "        print(f\"   âŒ {duplicates} duplicate games found\")\n",
    "    else:\n",
    "        print(\"   âœ… No duplicate games\")\n",
    "    \n",
    "    # Check 3: Chronological order\n",
    "    print(f\"\\nğŸ” Checking chronological order...\")\n",
    "    if not df_g['date'].is_monotonic_increasing:\n",
    "        issues.append(\"Games not sorted by date\")\n",
    "        print(\"   âŒ Games NOT in chronological order\")\n",
    "        print(\"   ğŸ’¡ Fix: df_g = df_g.sort_values('date').reset_index(drop=True)\")\n",
    "    else:\n",
    "        print(\"   âœ… Games in chronological order\")\n",
    "    \n",
    "    # Check 4: Score ranges\n",
    "    print(f\"\\nğŸ” Checking score ranges...\")\n",
    "    min_home = df_g['home_pts'].min()\n",
    "    max_home = df_g['home_pts'].max()\n",
    "    min_away = df_g['away_pts'].min()\n",
    "    max_away = df_g['away_pts'].max()\n",
    "    \n",
    "    print(f\"   Home scores: {min_home} to {max_home}\")\n",
    "    print(f\"   Away scores: {min_away} to {max_away}\")\n",
    "    \n",
    "    if min_home < 50 or min_away < 50:\n",
    "        warnings.append(f\"Unusually low scores found (min: {min(min_home, min_away)})\")\n",
    "        print(f\"   âš ï¸  Some scores < 50 points\")\n",
    "    \n",
    "    if max_home > 200 or max_away > 200:\n",
    "        warnings.append(f\"Unusually high scores found (max: {max(max_home, max_away)})\")\n",
    "        print(f\"   âš ï¸  Some scores > 200 points\")\n",
    "    \n",
    "    if len([w for w in warnings if 'score' in w.lower()]) == 0:\n",
    "        print(\"   âœ… Score ranges look reasonable (50-200)\")\n",
    "    \n",
    "    # Check 5: Data types\n",
    "    print(f\"\\nğŸ” Checking data types...\")\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df_g['date']):\n",
    "        warnings.append(\"'date' is not datetime type\")\n",
    "        print(f\"   âš ï¸  'date' is not datetime\")\n",
    "        print(f\"   ğŸ’¡ Fix: df_g['date'] = pd.to_datetime(df_g['date'])\")\n",
    "    else:\n",
    "        print(f\"   âœ… 'date' is datetime\")\n",
    "    \n",
    "    # Check 6: Season distribution\n",
    "    print(f\"\\nğŸ” Checking season distribution...\")\n",
    "    season_counts = df_g['home_season_id'].value_counts().sort_index()\n",
    "    print(f\"   Games per season:\")\n",
    "    for season, count in season_counts.items():\n",
    "        print(f\"      {season}: {count} games\")\n",
    "    \n",
    "    # Check 7: Home/Away team IDs are different\n",
    "    print(f\"\\nğŸ” Checking team matchups...\")\n",
    "    same_team = (df_g['home_team_id'] == df_g['away_team_id']).sum()\n",
    "    if same_team > 0:\n",
    "        issues.append(f\"{same_team} games where home_team_id == away_team_id\")\n",
    "        print(f\"   âŒ {same_team} games with same home/away team\")\n",
    "    else:\n",
    "        print(f\"   âœ… No games where team plays itself\")\n",
    "    \n",
    "    return {\n",
    "        'issues': issues,\n",
    "        'warnings': warnings,\n",
    "        'passed': len(issues) == 0\n",
    "    }\n",
    "\n",
    "\n",
    "def validate_players_dataframe(df_p):\n",
    "    \"\"\"\n",
    "    Check players dataframe for issues\n",
    "    \n",
    "    Args:\n",
    "        df_p: Players DataFrame (with your column structure)\n",
    "        \n",
    "    Returns:\n",
    "        dict: Validation results with issues found\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ” VALIDATING PLAYERS DATAFRAME\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    issues = []\n",
    "    warnings = []\n",
    "    \n",
    "    # Basic info\n",
    "    print(f\"\\nğŸ“Š Dataset Info:\")\n",
    "    print(f\"   Total records: {len(df_p)}\")\n",
    "    print(f\"   Date range: {df_p['game_date'].min()} to {df_p['game_date'].max()}\")\n",
    "    print(f\"   Unique players: {df_p['player_id'].nunique()}\")\n",
    "    print(f\"   Unique games: {df_p['game_id'].nunique()}\")\n",
    "    \n",
    "    # Check 1: Missing values in critical columns\n",
    "    print(f\"\\nğŸ” Checking for missing values...\")\n",
    "    critical_cols = ['player_id', 'game_id', 'team_id', 'game_date', 'min', 'pts']\n",
    "    \n",
    "    missing_found = False\n",
    "    for col in critical_cols:\n",
    "        missing = df_p[col].isna().sum()\n",
    "        if missing > 0:\n",
    "            issues.append(f\"{col}: {missing} missing values ({missing/len(df_p)*100:.1f}%)\")\n",
    "            missing_found = True\n",
    "            print(f\"   âŒ {col}: {missing} missing values\")\n",
    "    \n",
    "    if not missing_found:\n",
    "        print(\"   âœ… No missing values in critical columns\")\n",
    "    \n",
    "    # Check 2: Duplicate player-games\n",
    "    print(f\"\\nğŸ” Checking for duplicates...\")\n",
    "    duplicates = df_p.duplicated(subset=['player_id', 'game_id']).sum()\n",
    "    if duplicates > 0:\n",
    "        issues.append(f\"{duplicates} duplicate player-game records\")\n",
    "        print(f\"   âŒ {duplicates} duplicate player-game records\")\n",
    "        print(f\"   ğŸ’¡ Fix: df_p = df_p.drop_duplicates(subset=['player_id', 'game_id'])\")\n",
    "    else:\n",
    "        print(\"   âœ… No duplicate player-game records\")\n",
    "    \n",
    "    # Check 3: Minutes played ranges\n",
    "    print(f\"\\nğŸ” Checking minutes played...\")\n",
    "    min_minutes = df_p['min'].min()\n",
    "    max_minutes = df_p['min'].max()\n",
    "    zero_minutes = (df_p['min'] == 0).sum()\n",
    "    under_1_min = (df_p['min'] < 1).sum()\n",
    "    \n",
    "    print(f\"   Minutes range: {min_minutes} to {max_minutes}\")\n",
    "    print(f\"   Players with 0 minutes: {zero_minutes}\")\n",
    "    print(f\"   Players with <1 minute: {under_1_min}\")\n",
    "    \n",
    "    if max_minutes > 60:\n",
    "        over_60 = (df_p['min'] > 60).sum()\n",
    "        warnings.append(f\"{over_60} records with >60 minutes (overtime games)\")\n",
    "        print(f\"   âš ï¸  {over_60} records with >60 minutes (overtime)\")\n",
    "    \n",
    "    if zero_minutes > len(df_p) * 0.1:\n",
    "        warnings.append(f\"Many players with 0 minutes ({zero_minutes})\")\n",
    "        print(f\"   âš ï¸  {zero_minutes} players with 0 minutes (DNP)\")\n",
    "    \n",
    "    if under_1_min > 0 and under_1_min < len(df_p) * 0.05:\n",
    "        print(f\"   âœ… Most players have meaningful minutes\")\n",
    "    \n",
    "    # Check 4: Stats consistency\n",
    "    print(f\"\\nğŸ” Checking stats consistency...\")\n",
    "    \n",
    "    # FGM <= FGA\n",
    "    fgm_greater = (df_p['fgm'] > df_p['fga']).sum()\n",
    "    if fgm_greater > 0:\n",
    "        issues.append(f\"{fgm_greater} records where FGM > FGA (impossible)\")\n",
    "        print(f\"   âŒ {fgm_greater} records where FGM > FGA\")\n",
    "    else:\n",
    "        print(f\"   âœ… FGM <= FGA for all records\")\n",
    "    \n",
    "    # FG3M <= FG3A\n",
    "    fg3m_greater = (df_p['fg3m'] > df_p['fg3a']).sum()\n",
    "    if fg3m_greater > 0:\n",
    "        issues.append(f\"{fg3m_greater} records where FG3M > FG3A (impossible)\")\n",
    "        print(f\"   âŒ {fg3m_greater} records where FG3M > FG3A\")\n",
    "    else:\n",
    "        print(f\"   âœ… FG3M <= FG3A for all records\")\n",
    "    \n",
    "    # FTM <= FTA\n",
    "    ftm_greater = (df_p['ftm'] > df_p['fta']).sum()\n",
    "    if ftm_greater > 0:\n",
    "        issues.append(f\"{ftm_greater} records where FTM > FTA (impossible)\")\n",
    "        print(f\"   âŒ {ftm_greater} records where FTM > FTA\")\n",
    "    else:\n",
    "        print(f\"   âœ… FTM <= FTA for all records\")\n",
    "    \n",
    "    # FG3M <= FGM (3-pointers are subset of all field goals)\n",
    "    fg3m_greater_fgm = (df_p['fg3m'] > df_p['fgm']).sum()\n",
    "    if fg3m_greater_fgm > 0:\n",
    "        issues.append(f\"{fg3m_greater_fgm} records where FG3M > FGM (impossible)\")\n",
    "        print(f\"   âŒ {fg3m_greater_fgm} records where FG3M > FGM\")\n",
    "    else:\n",
    "        print(f\"   âœ… FG3M <= FGM for all records\")\n",
    "    \n",
    "    # Check 5: Negative values\n",
    "    print(f\"\\nğŸ” Checking for negative values...\")\n",
    "    stat_cols = ['min', 'pts', 'reb', 'ast', 'stl', 'blk', 'fgm', 'fga']\n",
    "    negative_found = False\n",
    "    \n",
    "    for col in stat_cols:\n",
    "        negatives = (df_p[col] < 0).sum()\n",
    "        if negatives > 0:\n",
    "            issues.append(f\"{col}: {negatives} negative values\")\n",
    "            negative_found = True\n",
    "            print(f\"   âŒ {col}: {negatives} negative values\")\n",
    "    \n",
    "    if not negative_found:\n",
    "        print(\"   âœ… No negative values in stats\")\n",
    "    \n",
    "    # Check 6: Chronological order\n",
    "    print(f\"\\nğŸ” Checking chronological order...\")\n",
    "    if not df_p['game_date'].is_monotonic_increasing:\n",
    "        warnings.append(\"Players data not sorted by date\")\n",
    "        print(\"   âš ï¸  Data NOT in chronological order\")\n",
    "        print(\"   ğŸ’¡ Fix: df_p = df_p.sort_values('game_date').reset_index(drop=True)\")\n",
    "    else:\n",
    "        print(\"   âœ… Data in chronological order\")\n",
    "    \n",
    "    # Check 7: Data types\n",
    "    print(f\"\\nğŸ” Checking data types...\")\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df_p['game_date']):\n",
    "        warnings.append(\"'game_date' is not datetime type\")\n",
    "        print(f\"   âš ï¸  'game_date' is not datetime\")\n",
    "        print(f\"   ğŸ’¡ Fix: df_p['game_date'] = pd.to_datetime(df_p['game_date'])\")\n",
    "    else:\n",
    "        print(f\"   âœ… 'game_date' is datetime\")\n",
    "    \n",
    "    return {\n",
    "        'issues': issues,\n",
    "        'warnings': warnings,\n",
    "        'passed': len(issues) == 0\n",
    "    }\n",
    "\n",
    "\n",
    "def validate_consistency(df_g, df_p):\n",
    "    \"\"\"\n",
    "    Check consistency between games and players dataframes\n",
    "    \n",
    "    Args:\n",
    "        df_g: Games DataFrame\n",
    "        df_p: Players DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        dict: Validation results\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ” VALIDATING CROSS-DATAFRAME CONSISTENCY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    issues = []\n",
    "    warnings = []\n",
    "    \n",
    "    # Check 1: Date range overlap\n",
    "    print(f\"\\nğŸ” Checking date ranges...\")\n",
    "    games_start = df_g['date'].min()\n",
    "    games_end = df_g['date'].max()\n",
    "    players_start = df_p['game_date'].min()\n",
    "    players_end = df_p['game_date'].max()\n",
    "    \n",
    "    print(f\"   Games:   {games_start} to {games_end}\")\n",
    "    print(f\"   Players: {players_start} to {players_end}\")\n",
    "    \n",
    "    if players_start > games_start:\n",
    "        warnings.append(f\"Player data starts later than games ({players_start} vs {games_start})\")\n",
    "        print(f\"   âš ï¸  Player data starts later than games\")\n",
    "    \n",
    "    if players_end < games_end:\n",
    "        warnings.append(f\"Player data ends earlier than games ({players_end} vs {games_end})\")\n",
    "        print(f\"   âš ï¸  Player data ends earlier than games\")\n",
    "    \n",
    "    if len(warnings) == 0:\n",
    "        print(f\"   âœ… Date ranges fully overlap\")\n",
    "    \n",
    "    # Check 2: Game IDs consistency\n",
    "    print(f\"\\nğŸ” Checking game_id consistency...\")\n",
    "    games_ids = set(df_g['game_id'].astype(str).unique())\n",
    "    players_ids = set(df_p['game_id'].astype(str).unique())\n",
    "    \n",
    "    games_only = games_ids - players_ids\n",
    "    players_only = players_ids - games_ids\n",
    "    overlap = games_ids & players_ids\n",
    "    \n",
    "    print(f\"   Games with player data: {len(overlap)} / {len(games_ids)}\")\n",
    "    \n",
    "    if len(games_only) > 0:\n",
    "        pct = len(games_only) / len(games_ids) * 100\n",
    "        warnings.append(f\"{len(games_only)} games ({pct:.1f}%) have no player data\")\n",
    "        print(f\"   âš ï¸  {len(games_only)} games missing player data\")\n",
    "    \n",
    "    if len(players_only) > 0:\n",
    "        warnings.append(f\"{len(players_only)} games in player data not in games data\")\n",
    "        print(f\"   âš ï¸  {len(players_only)} orphan games in player data\")\n",
    "    \n",
    "    if len(games_only) == 0 and len(players_only) == 0:\n",
    "        print(f\"   âœ… Perfect game_id alignment\")\n",
    "    \n",
    "    # Check 3: Score consistency (sample)\n",
    "    print(f\"\\nğŸ” Checking score consistency (sample of 10 games)...\")\n",
    "    sample_games = df_g.sample(min(10, len(df_g)))\n",
    "    \n",
    "    mismatches = 0\n",
    "    for _, game in sample_games.iterrows():\n",
    "        game_players = df_p[df_p['game_id'].astype(str) == str(game['game_id'])]\n",
    "        \n",
    "        home_players = game_players[game_players['team_id'] == game['home_team_id']]\n",
    "        away_players = game_players[game_players['team_id'] == game['away_team_id']]\n",
    "        \n",
    "        if len(home_players) > 0:\n",
    "            home_total = home_players['pts'].sum()\n",
    "            if abs(home_total - game['home_pts']) > 1:\n",
    "                mismatches += 1\n",
    "        \n",
    "        if len(away_players) > 0:\n",
    "            away_total = away_players['pts'].sum()\n",
    "            if abs(away_total - game['away_pts']) > 1:\n",
    "                mismatches += 1\n",
    "    \n",
    "    if mismatches > 0:\n",
    "        warnings.append(f\"Score mismatches found in {mismatches}/20 checks\")\n",
    "        print(f\"   âš ï¸  {mismatches}/20 score mismatches (player sum â‰  team total)\")\n",
    "    else:\n",
    "        print(f\"   âœ… Player points sum to team totals\")\n",
    "    \n",
    "    # Check 4: Team IDs match\n",
    "    print(f\"\\nğŸ” Checking team IDs...\")\n",
    "    games_teams = set(df_g['home_team_id'].unique()) | set(df_g['away_team_id'].unique())\n",
    "    player_teams = set(df_p['team_id'].unique())\n",
    "    \n",
    "    teams_only_in_games = games_teams - player_teams\n",
    "    teams_only_in_players = player_teams - games_teams\n",
    "    \n",
    "    if len(teams_only_in_games) > 0:\n",
    "        warnings.append(f\"{len(teams_only_in_games)} teams in games but not in player data\")\n",
    "        print(f\"   âš ï¸  {len(teams_only_in_games)} teams in games but not players\")\n",
    "    \n",
    "    if len(teams_only_in_players) > 0:\n",
    "        warnings.append(f\"{len(teams_only_in_players)} teams in player data but not games\")\n",
    "        print(f\"   âš ï¸  {len(teams_only_in_players)} teams in players but not games\")\n",
    "    \n",
    "    if len(teams_only_in_games) == 0 and len(teams_only_in_players) == 0:\n",
    "        print(f\"   âœ… Team IDs match across dataframes\")\n",
    "    \n",
    "    return {\n",
    "        'issues': issues,\n",
    "        'warnings': warnings,\n",
    "        'passed': len(issues) == 0\n",
    "    }\n",
    "\n",
    "\n",
    "def validate_all(df_g, df_p):\n",
    "    \"\"\"\n",
    "    Run all validation checks\n",
    "    \n",
    "    Args:\n",
    "        df_g: Games DataFrame\n",
    "        df_p: Players DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        dict: Complete validation results\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"ğŸ” \"*30)\n",
    "    print(\"STARTING COMPLETE DATA VALIDATION\")\n",
    "    print(\"ğŸ” \"*30)\n",
    "    \n",
    "    # Run all validations\n",
    "    games_results = validate_games_dataframe(df_g)\n",
    "    players_results = validate_players_dataframe(df_p)\n",
    "    consistency_results = validate_consistency(df_g, df_p)\n",
    "    \n",
    "    # Combine results\n",
    "    all_issues = (games_results['issues'] + \n",
    "                  players_results['issues'] + \n",
    "                  consistency_results['issues'])\n",
    "    \n",
    "    all_warnings = (games_results['warnings'] + \n",
    "                    players_results['warnings'] + \n",
    "                    consistency_results['warnings'])\n",
    "    \n",
    "    # Final report\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ“‹ VALIDATION SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if len(all_issues) == 0:\n",
    "        print(\"âœ… NO CRITICAL ISSUES FOUND\")\n",
    "    else:\n",
    "        print(f\"âŒ {len(all_issues)} CRITICAL ISSUES FOUND:\")\n",
    "        for i, issue in enumerate(all_issues, 1):\n",
    "            print(f\"   {i}. {issue}\")\n",
    "    \n",
    "    if len(all_warnings) > 0:\n",
    "        print(f\"\\nâš ï¸  {len(all_warnings)} WARNINGS:\")\n",
    "        for i, warning in enumerate(all_warnings, 1):\n",
    "            print(f\"   {i}. {warning}\")\n",
    "    else:\n",
    "        print(\"\\nâœ… NO WARNINGS\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    \n",
    "    if len(all_issues) == 0 and len(all_warnings) == 0:\n",
    "        print(\"ğŸ‰ DATA IS READY FOR MODELING!\")\n",
    "    elif len(all_issues) == 0:\n",
    "        print(\"âœ… DATA IS USABLE (with minor warnings)\")\n",
    "    else:\n",
    "        print(\"âŒ FIX CRITICAL ISSUES BEFORE PROCEEDING\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return {\n",
    "        'games': games_results,\n",
    "        'players': players_results,\n",
    "        'consistency': consistency_results,\n",
    "        'all_issues': all_issues,\n",
    "        'all_warnings': all_warnings,\n",
    "        'passed': len(all_issues) == 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "427b0c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” \n",
      "STARTING COMPLETE DATA VALIDATION\n",
      "ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” ğŸ” \n",
      "\n",
      "============================================================\n",
      "ğŸ” VALIDATING GAMES DATAFRAME\n",
      "============================================================\n",
      "\n",
      "ğŸ“Š Dataset Info:\n",
      "   Total games: 7054\n",
      "   Date range: 2019-10-22 to 2025-04-13\n",
      "   Unique teams: 30\n",
      "\n",
      "ğŸ” Checking for missing values...\n",
      "   âœ… No missing values in critical columns\n",
      "\n",
      "ğŸ” Checking for duplicates...\n",
      "   âœ… No duplicate games\n",
      "\n",
      "ğŸ” Checking chronological order...\n",
      "   âœ… Games in chronological order\n",
      "\n",
      "ğŸ” Checking score ranges...\n",
      "   Home scores: 73 to 175\n",
      "   Away scores: 67 to 176\n",
      "   âœ… Score ranges look reasonable (50-200)\n",
      "\n",
      "ğŸ” Checking data types...\n",
      "   âš ï¸  'date' is not datetime\n",
      "   ğŸ’¡ Fix: df_g['date'] = pd.to_datetime(df_g['date'])\n",
      "\n",
      "ğŸ” Checking season distribution...\n",
      "   Games per season:\n",
      "      22019: 1059 games\n",
      "      22020: 1080 games\n",
      "      22021: 1230 games\n",
      "      22022: 1230 games\n",
      "      22023: 1230 games\n",
      "      22024: 1225 games\n",
      "\n",
      "ğŸ” Checking team matchups...\n",
      "   âœ… No games where team plays itself\n",
      "\n",
      "============================================================\n",
      "ğŸ” VALIDATING PLAYERS DATAFRAME\n",
      "============================================================\n",
      "\n",
      "ğŸ“Š Dataset Info:\n",
      "   Total records: 150087\n",
      "   Date range: 2019-10-22T00:00:00 to 2025-04-13T00:00:00\n",
      "   Unique players: 1068\n",
      "   Unique games: 7059\n",
      "\n",
      "ğŸ” Checking for missing values...\n",
      "   âœ… No missing values in critical columns\n",
      "\n",
      "ğŸ” Checking for duplicates...\n",
      "   âœ… No duplicate player-game records\n",
      "\n",
      "ğŸ” Checking minutes played...\n",
      "   Minutes range: 0.0 to 56.516666666666666\n",
      "   Players with 0 minutes: 11\n",
      "   Players with <1 minute: 1362\n",
      "   âœ… Most players have meaningful minutes\n",
      "\n",
      "ğŸ” Checking stats consistency...\n",
      "   âœ… FGM <= FGA for all records\n",
      "   âœ… FG3M <= FG3A for all records\n",
      "   âœ… FTM <= FTA for all records\n",
      "   âœ… FG3M <= FGM for all records\n",
      "\n",
      "ğŸ” Checking for negative values...\n",
      "   âœ… No negative values in stats\n",
      "\n",
      "ğŸ” Checking chronological order...\n",
      "   âœ… Data in chronological order\n",
      "\n",
      "ğŸ” Checking data types...\n",
      "   âš ï¸  'game_date' is not datetime\n",
      "   ğŸ’¡ Fix: df_p['game_date'] = pd.to_datetime(df_p['game_date'])\n",
      "\n",
      "============================================================\n",
      "ğŸ” VALIDATING CROSS-DATAFRAME CONSISTENCY\n",
      "============================================================\n",
      "\n",
      "ğŸ” Checking date ranges...\n",
      "   Games:   2019-10-22 to 2025-04-13\n",
      "   Players: 2019-10-22T00:00:00 to 2025-04-13T00:00:00\n",
      "   âš ï¸  Player data starts later than games\n",
      "\n",
      "ğŸ” Checking game_id consistency...\n",
      "   Games with player data: 7054 / 7054\n",
      "   âš ï¸  5 orphan games in player data\n",
      "\n",
      "ğŸ” Checking score consistency (sample of 10 games)...\n",
      "   âœ… Player points sum to team totals\n",
      "\n",
      "ğŸ” Checking team IDs...\n",
      "   âš ï¸  30 teams in games but not players\n",
      "   âš ï¸  30 teams in players but not games\n",
      "\n",
      "============================================================\n",
      "ğŸ“‹ VALIDATION SUMMARY\n",
      "============================================================\n",
      "âœ… NO CRITICAL ISSUES FOUND\n",
      "\n",
      "âš ï¸  6 WARNINGS:\n",
      "   1. 'date' is not datetime type\n",
      "   2. 'game_date' is not datetime type\n",
      "   3. Player data starts later than games (2019-10-22T00:00:00 vs 2019-10-22)\n",
      "   4. 5 games in player data not in games data\n",
      "   5. 30 teams in games but not in player data\n",
      "   6. 30 teams in player data but not games\n",
      "\n",
      "============================================================\n",
      "âœ… DATA IS USABLE (with minor warnings)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "results = validate_all(df_g, df_p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
