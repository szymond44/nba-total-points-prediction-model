{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc3f02e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b686e301",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from data.api_fetcher import ApiFetcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9bc132ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = ApiFetcher(starting_year=2019, ending_year=2025)\n",
    "df_p = api.get_dataframe('playerstats', all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "826322f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_g = api.get_dataframe('leaguegamelog', all = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f2d2a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['season_year', 'player_id', 'player_name', 'nickname', 'team_id',\n",
      "       'team_abbreviation', 'team_name', 'game_id', 'game_date', 'matchup',\n",
      "       'wl', 'min', 'fgm', 'fga', 'fg_pct', 'fg3m', 'fg3a', 'fg3_pct', 'ftm',\n",
      "       'fta', 'ft_pct', 'oreb', 'dreb', 'reb', 'ast', 'tov', 'stl', 'blk',\n",
      "       'blka', 'pf', 'pfd', 'pts', 'plus_minus', 'nba_fantasy_pts', 'dd2',\n",
      "       'td3', 'wnba_fantasy_pts', 'gp_rank', 'w_rank', 'l_rank', 'w_pct_rank',\n",
      "       'min_rank', 'fgm_rank', 'fga_rank', 'fg_pct_rank', 'fg3m_rank',\n",
      "       'fg3a_rank', 'fg3_pct_rank', 'ftm_rank', 'fta_rank', 'ft_pct_rank',\n",
      "       'oreb_rank', 'dreb_rank', 'reb_rank', 'ast_rank', 'tov_rank',\n",
      "       'stl_rank', 'blk_rank', 'blka_rank', 'pf_rank', 'pfd_rank', 'pts_rank',\n",
      "       'plus_minus_rank', 'nba_fantasy_pts_rank', 'dd2_rank', 'td3_rank',\n",
      "       'wnba_fantasy_pts_rank', 'available_flag', 'min_sec', 'team_count',\n",
      "       'season', 'ts_pct', 'ast_to_ratio', 'pts_per_fga', 'reb_per_min',\n",
      "       'pts_ast_composite', 'usage_composite', 'fg3a_rate', 'fta_rate',\n",
      "       'is_win', 'is_home'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_p.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bee7821a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['game_id', 'date', 'home_team', 'away_team', 'home_season_id',\n",
      "       'home_team_id', 'home_team_abbreviation', 'home_wl', 'home_min',\n",
      "       'home_fgm', 'home_fga', 'home_fg_pct', 'home_fg3m', 'home_fg3a',\n",
      "       'home_fg3_pct', 'home_ftm', 'home_fta', 'home_ft_pct', 'home_oreb',\n",
      "       'home_dreb', 'home_reb', 'home_ast', 'home_stl', 'home_blk', 'home_tov',\n",
      "       'home_pf', 'home_pts', 'home_plus_minus', 'home_video_available',\n",
      "       'away_season_id', 'away_team_id', 'away_team_abbreviation', 'away_wl',\n",
      "       'away_min', 'away_fgm', 'away_fga', 'away_fg_pct', 'away_fg3m',\n",
      "       'away_fg3a', 'away_fg3_pct', 'away_ftm', 'away_fta', 'away_ft_pct',\n",
      "       'away_oreb', 'away_dreb', 'away_reb', 'away_ast', 'away_stl',\n",
      "       'away_blk', 'away_tov', 'away_pf', 'away_pts', 'away_plus_minus',\n",
      "       'away_video_available'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_g.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e883b26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data validation - checks for errors and inconsistencies\n",
    "Does NOT modify data, only reports issues\n",
    "Customized for your specific column structure\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def validate_games_dataframe(df_g):\n",
    "    \"\"\"\n",
    "    Check games dataframe for issues\n",
    "    \n",
    "    Args:\n",
    "        df_g: Games DataFrame (with your column structure)\n",
    "        \n",
    "    Returns:\n",
    "        dict: Validation results with issues found\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üîç VALIDATING GAMES DATAFRAME\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    issues = []\n",
    "    warnings = []\n",
    "    \n",
    "    # Basic info\n",
    "    print(f\"\\nüìä Dataset Info:\")\n",
    "    print(f\"   Total games: {len(df_g)}\")\n",
    "    print(f\"   Date range: {df_g['date'].min()} to {df_g['date'].max()}\")\n",
    "    print(f\"   Unique teams: {df_g['home_team_id'].nunique()}\")\n",
    "    \n",
    "    # Check 1: Missing values\n",
    "    print(f\"\\nüîç Checking for missing values...\")\n",
    "    critical_cols = ['game_id', 'date', 'home_team_id', 'away_team_id', \n",
    "                     'home_pts', 'away_pts']\n",
    "    \n",
    "    missing_found = False\n",
    "    for col in critical_cols:\n",
    "        if col not in df_g.columns:\n",
    "            issues.append(f\"Missing column: {col}\")\n",
    "            missing_found = True\n",
    "        else:\n",
    "            missing = df_g[col].isna().sum()\n",
    "            if missing > 0:\n",
    "                issues.append(f\"{col}: {missing} missing values\")\n",
    "                missing_found = True\n",
    "                print(f\"   ‚ùå {col}: {missing} missing values\")\n",
    "    \n",
    "    if not missing_found:\n",
    "        print(\"   ‚úÖ No missing values in critical columns\")\n",
    "    \n",
    "    # Check 2: Duplicate games\n",
    "    print(f\"\\nüîç Checking for duplicates...\")\n",
    "    duplicates = df_g['game_id'].duplicated().sum()\n",
    "    if duplicates > 0:\n",
    "        issues.append(f\"{duplicates} duplicate game_ids\")\n",
    "        print(f\"   ‚ùå {duplicates} duplicate games found\")\n",
    "    else:\n",
    "        print(\"   ‚úÖ No duplicate games\")\n",
    "    \n",
    "    # Check 3: Chronological order\n",
    "    print(f\"\\nüîç Checking chronological order...\")\n",
    "    if not df_g['date'].is_monotonic_increasing:\n",
    "        issues.append(\"Games not sorted by date\")\n",
    "        print(\"   ‚ùå Games NOT in chronological order\")\n",
    "        print(\"   üí° Fix: df_g = df_g.sort_values('date').reset_index(drop=True)\")\n",
    "    else:\n",
    "        print(\"   ‚úÖ Games in chronological order\")\n",
    "    \n",
    "    # Check 4: Score ranges\n",
    "    print(f\"\\nüîç Checking score ranges...\")\n",
    "    min_home = df_g['home_pts'].min()\n",
    "    max_home = df_g['home_pts'].max()\n",
    "    min_away = df_g['away_pts'].min()\n",
    "    max_away = df_g['away_pts'].max()\n",
    "    \n",
    "    print(f\"   Home scores: {min_home} to {max_home}\")\n",
    "    print(f\"   Away scores: {min_away} to {max_away}\")\n",
    "    \n",
    "    if min_home < 50 or min_away < 50:\n",
    "        warnings.append(f\"Unusually low scores found (min: {min(min_home, min_away)})\")\n",
    "        print(f\"   ‚ö†Ô∏è  Some scores < 50 points\")\n",
    "    \n",
    "    if max_home > 200 or max_away > 200:\n",
    "        warnings.append(f\"Unusually high scores found (max: {max(max_home, max_away)})\")\n",
    "        print(f\"   ‚ö†Ô∏è  Some scores > 200 points\")\n",
    "    \n",
    "    if len([w for w in warnings if 'score' in w.lower()]) == 0:\n",
    "        print(\"   ‚úÖ Score ranges look reasonable (50-200)\")\n",
    "    \n",
    "    # Check 5: Data types\n",
    "    print(f\"\\nüîç Checking data types...\")\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df_g['date']):\n",
    "        warnings.append(\"'date' is not datetime type\")\n",
    "        print(f\"   ‚ö†Ô∏è  'date' is not datetime\")\n",
    "        print(f\"   üí° Fix: df_g['date'] = pd.to_datetime(df_g['date'])\")\n",
    "    else:\n",
    "        print(f\"   ‚úÖ 'date' is datetime\")\n",
    "    \n",
    "    # Check 6: Season distribution\n",
    "    print(f\"\\nüîç Checking season distribution...\")\n",
    "    season_counts = df_g['home_season_id'].value_counts().sort_index()\n",
    "    print(f\"   Games per season:\")\n",
    "    for season, count in season_counts.items():\n",
    "        print(f\"      {season}: {count} games\")\n",
    "    \n",
    "    # Check 7: Home/Away team IDs are different\n",
    "    print(f\"\\nüîç Checking team matchups...\")\n",
    "    same_team = (df_g['home_team_id'] == df_g['away_team_id']).sum()\n",
    "    if same_team > 0:\n",
    "        issues.append(f\"{same_team} games where home_team_id == away_team_id\")\n",
    "        print(f\"   ‚ùå {same_team} games with same home/away team\")\n",
    "    else:\n",
    "        print(f\"   ‚úÖ No games where team plays itself\")\n",
    "    \n",
    "    return {\n",
    "        'issues': issues,\n",
    "        'warnings': warnings,\n",
    "        'passed': len(issues) == 0\n",
    "    }\n",
    "\n",
    "\n",
    "def validate_players_dataframe(df_p):\n",
    "    \"\"\"\n",
    "    Check players dataframe for issues\n",
    "    \n",
    "    Args:\n",
    "        df_p: Players DataFrame (with your column structure)\n",
    "        \n",
    "    Returns:\n",
    "        dict: Validation results with issues found\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üîç VALIDATING PLAYERS DATAFRAME\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    issues = []\n",
    "    warnings = []\n",
    "    \n",
    "    # Basic info\n",
    "    print(f\"\\nüìä Dataset Info:\")\n",
    "    print(f\"   Total records: {len(df_p)}\")\n",
    "    print(f\"   Date range: {df_p['game_date'].min()} to {df_p['game_date'].max()}\")\n",
    "    print(f\"   Unique players: {df_p['player_id'].nunique()}\")\n",
    "    print(f\"   Unique games: {df_p['game_id'].nunique()}\")\n",
    "    \n",
    "    # Check 1: Missing values in critical columns\n",
    "    print(f\"\\nüîç Checking for missing values...\")\n",
    "    critical_cols = ['player_id', 'game_id', 'team_id', 'game_date', 'min', 'pts']\n",
    "    \n",
    "    missing_found = False\n",
    "    for col in critical_cols:\n",
    "        missing = df_p[col].isna().sum()\n",
    "        if missing > 0:\n",
    "            issues.append(f\"{col}: {missing} missing values ({missing/len(df_p)*100:.1f}%)\")\n",
    "            missing_found = True\n",
    "            print(f\"   ‚ùå {col}: {missing} missing values\")\n",
    "    \n",
    "    if not missing_found:\n",
    "        print(\"   ‚úÖ No missing values in critical columns\")\n",
    "    \n",
    "    # Check 2: Duplicate player-games\n",
    "    print(f\"\\nüîç Checking for duplicates...\")\n",
    "    duplicates = df_p.duplicated(subset=['player_id', 'game_id']).sum()\n",
    "    if duplicates > 0:\n",
    "        issues.append(f\"{duplicates} duplicate player-game records\")\n",
    "        print(f\"   ‚ùå {duplicates} duplicate player-game records\")\n",
    "        print(f\"   üí° Fix: df_p = df_p.drop_duplicates(subset=['player_id', 'game_id'])\")\n",
    "    else:\n",
    "        print(\"   ‚úÖ No duplicate player-game records\")\n",
    "    \n",
    "    # Check 3: Minutes played ranges\n",
    "    print(f\"\\nüîç Checking minutes played...\")\n",
    "    min_minutes = df_p['min'].min()\n",
    "    max_minutes = df_p['min'].max()\n",
    "    zero_minutes = (df_p['min'] == 0).sum()\n",
    "    under_1_min = (df_p['min'] < 1).sum()\n",
    "    \n",
    "    print(f\"   Minutes range: {min_minutes} to {max_minutes}\")\n",
    "    print(f\"   Players with 0 minutes: {zero_minutes}\")\n",
    "    print(f\"   Players with <1 minute: {under_1_min}\")\n",
    "    \n",
    "    if max_minutes > 60:\n",
    "        over_60 = (df_p['min'] > 60).sum()\n",
    "        warnings.append(f\"{over_60} records with >60 minutes (overtime games)\")\n",
    "        print(f\"   ‚ö†Ô∏è  {over_60} records with >60 minutes (overtime)\")\n",
    "    \n",
    "    if zero_minutes > len(df_p) * 0.1:\n",
    "        warnings.append(f\"Many players with 0 minutes ({zero_minutes})\")\n",
    "        print(f\"   ‚ö†Ô∏è  {zero_minutes} players with 0 minutes (DNP)\")\n",
    "    \n",
    "    if under_1_min > 0 and under_1_min < len(df_p) * 0.05:\n",
    "        print(f\"   ‚úÖ Most players have meaningful minutes\")\n",
    "    \n",
    "    # Check 4: Stats consistency\n",
    "    print(f\"\\nüîç Checking stats consistency...\")\n",
    "    \n",
    "    # FGM <= FGA\n",
    "    fgm_greater = (df_p['fgm'] > df_p['fga']).sum()\n",
    "    if fgm_greater > 0:\n",
    "        issues.append(f\"{fgm_greater} records where FGM > FGA (impossible)\")\n",
    "        print(f\"   ‚ùå {fgm_greater} records where FGM > FGA\")\n",
    "    else:\n",
    "        print(f\"   ‚úÖ FGM <= FGA for all records\")\n",
    "    \n",
    "    # FG3M <= FG3A\n",
    "    fg3m_greater = (df_p['fg3m'] > df_p['fg3a']).sum()\n",
    "    if fg3m_greater > 0:\n",
    "        issues.append(f\"{fg3m_greater} records where FG3M > FG3A (impossible)\")\n",
    "        print(f\"   ‚ùå {fg3m_greater} records where FG3M > FG3A\")\n",
    "    else:\n",
    "        print(f\"   ‚úÖ FG3M <= FG3A for all records\")\n",
    "    \n",
    "    # FTM <= FTA\n",
    "    ftm_greater = (df_p['ftm'] > df_p['fta']).sum()\n",
    "    if ftm_greater > 0:\n",
    "        issues.append(f\"{ftm_greater} records where FTM > FTA (impossible)\")\n",
    "        print(f\"   ‚ùå {ftm_greater} records where FTM > FTA\")\n",
    "    else:\n",
    "        print(f\"   ‚úÖ FTM <= FTA for all records\")\n",
    "    \n",
    "    # FG3M <= FGM (3-pointers are subset of all field goals)\n",
    "    fg3m_greater_fgm = (df_p['fg3m'] > df_p['fgm']).sum()\n",
    "    if fg3m_greater_fgm > 0:\n",
    "        issues.append(f\"{fg3m_greater_fgm} records where FG3M > FGM (impossible)\")\n",
    "        print(f\"   ‚ùå {fg3m_greater_fgm} records where FG3M > FGM\")\n",
    "    else:\n",
    "        print(f\"   ‚úÖ FG3M <= FGM for all records\")\n",
    "    \n",
    "    # Check 5: Negative values\n",
    "    print(f\"\\nüîç Checking for negative values...\")\n",
    "    stat_cols = ['min', 'pts', 'reb', 'ast', 'stl', 'blk', 'fgm', 'fga']\n",
    "    negative_found = False\n",
    "    \n",
    "    for col in stat_cols:\n",
    "        negatives = (df_p[col] < 0).sum()\n",
    "        if negatives > 0:\n",
    "            issues.append(f\"{col}: {negatives} negative values\")\n",
    "            negative_found = True\n",
    "            print(f\"   ‚ùå {col}: {negatives} negative values\")\n",
    "    \n",
    "    if not negative_found:\n",
    "        print(\"   ‚úÖ No negative values in stats\")\n",
    "    \n",
    "    # Check 6: Chronological order\n",
    "    print(f\"\\nüîç Checking chronological order...\")\n",
    "    if not df_p['game_date'].is_monotonic_increasing:\n",
    "        warnings.append(\"Players data not sorted by date\")\n",
    "        print(\"   ‚ö†Ô∏è  Data NOT in chronological order\")\n",
    "        print(\"   üí° Fix: df_p = df_p.sort_values('game_date').reset_index(drop=True)\")\n",
    "    else:\n",
    "        print(\"   ‚úÖ Data in chronological order\")\n",
    "    \n",
    "    # Check 7: Data types\n",
    "    print(f\"\\nüîç Checking data types...\")\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df_p['game_date']):\n",
    "        warnings.append(\"'game_date' is not datetime type\")\n",
    "        print(f\"   ‚ö†Ô∏è  'game_date' is not datetime\")\n",
    "        print(f\"   üí° Fix: df_p['game_date'] = pd.to_datetime(df_p['game_date'])\")\n",
    "    else:\n",
    "        print(f\"   ‚úÖ 'game_date' is datetime\")\n",
    "    \n",
    "    return {\n",
    "        'issues': issues,\n",
    "        'warnings': warnings,\n",
    "        'passed': len(issues) == 0\n",
    "    }\n",
    "\n",
    "\n",
    "def validate_consistency(df_g, df_p):\n",
    "    \"\"\"\n",
    "    Check consistency between games and players dataframes\n",
    "    \n",
    "    Args:\n",
    "        df_g: Games DataFrame\n",
    "        df_p: Players DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        dict: Validation results\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üîç VALIDATING CROSS-DATAFRAME CONSISTENCY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    issues = []\n",
    "    warnings = []\n",
    "    \n",
    "    # Check 1: Date range overlap\n",
    "    print(f\"\\nüîç Checking date ranges...\")\n",
    "    games_start = df_g['date'].min()\n",
    "    games_end = df_g['date'].max()\n",
    "    players_start = df_p['game_date'].min()\n",
    "    players_end = df_p['game_date'].max()\n",
    "    \n",
    "    print(f\"   Games:   {games_start} to {games_end}\")\n",
    "    print(f\"   Players: {players_start} to {players_end}\")\n",
    "    \n",
    "    if players_start > games_start:\n",
    "        warnings.append(f\"Player data starts later than games ({players_start} vs {games_start})\")\n",
    "        print(f\"   ‚ö†Ô∏è  Player data starts later than games\")\n",
    "    \n",
    "    if players_end < games_end:\n",
    "        warnings.append(f\"Player data ends earlier than games ({players_end} vs {games_end})\")\n",
    "        print(f\"   ‚ö†Ô∏è  Player data ends earlier than games\")\n",
    "    \n",
    "    if len(warnings) == 0:\n",
    "        print(f\"   ‚úÖ Date ranges fully overlap\")\n",
    "    \n",
    "    # Check 2: Game IDs consistency\n",
    "    print(f\"\\nüîç Checking game_id consistency...\")\n",
    "    games_ids = set(df_g['game_id'].astype(str).unique())\n",
    "    players_ids = set(df_p['game_id'].astype(str).unique())\n",
    "    \n",
    "    games_only = games_ids - players_ids\n",
    "    players_only = players_ids - games_ids\n",
    "    overlap = games_ids & players_ids\n",
    "    \n",
    "    print(f\"   Games with player data: {len(overlap)} / {len(games_ids)}\")\n",
    "    \n",
    "    if len(games_only) > 0:\n",
    "        pct = len(games_only) / len(games_ids) * 100\n",
    "        warnings.append(f\"{len(games_only)} games ({pct:.1f}%) have no player data\")\n",
    "        print(f\"   ‚ö†Ô∏è  {len(games_only)} games missing player data\")\n",
    "    \n",
    "    if len(players_only) > 0:\n",
    "        warnings.append(f\"{len(players_only)} games in player data not in games data\")\n",
    "        print(f\"   ‚ö†Ô∏è  {len(players_only)} orphan games in player data\")\n",
    "    \n",
    "    if len(games_only) == 0 and len(players_only) == 0:\n",
    "        print(f\"   ‚úÖ Perfect game_id alignment\")\n",
    "    \n",
    "    # Check 3: Score consistency (sample)\n",
    "    print(f\"\\nüîç Checking score consistency (sample of 10 games)...\")\n",
    "    sample_games = df_g.sample(min(10, len(df_g)))\n",
    "    \n",
    "    mismatches = 0\n",
    "    for _, game in sample_games.iterrows():\n",
    "        game_players = df_p[df_p['game_id'].astype(str) == str(game['game_id'])]\n",
    "        \n",
    "        home_players = game_players[game_players['team_id'] == game['home_team_id']]\n",
    "        away_players = game_players[game_players['team_id'] == game['away_team_id']]\n",
    "        \n",
    "        if len(home_players) > 0:\n",
    "            home_total = home_players['pts'].sum()\n",
    "            if abs(home_total - game['home_pts']) > 1:\n",
    "                mismatches += 1\n",
    "        \n",
    "        if len(away_players) > 0:\n",
    "            away_total = away_players['pts'].sum()\n",
    "            if abs(away_total - game['away_pts']) > 1:\n",
    "                mismatches += 1\n",
    "    \n",
    "    if mismatches > 0:\n",
    "        warnings.append(f\"Score mismatches found in {mismatches}/20 checks\")\n",
    "        print(f\"   ‚ö†Ô∏è  {mismatches}/20 score mismatches (player sum ‚â† team total)\")\n",
    "    else:\n",
    "        print(f\"   ‚úÖ Player points sum to team totals\")\n",
    "    \n",
    "    # Check 4: Team IDs match\n",
    "    print(f\"\\nüîç Checking team IDs...\")\n",
    "    games_teams = set(df_g['home_team_id'].unique()) | set(df_g['away_team_id'].unique())\n",
    "    player_teams = set(df_p['team_id'].unique())\n",
    "    \n",
    "    teams_only_in_games = games_teams - player_teams\n",
    "    teams_only_in_players = player_teams - games_teams\n",
    "    \n",
    "    if len(teams_only_in_games) > 0:\n",
    "        warnings.append(f\"{len(teams_only_in_games)} teams in games but not in player data\")\n",
    "        print(f\"   ‚ö†Ô∏è  {len(teams_only_in_games)} teams in games but not players\")\n",
    "    \n",
    "    if len(teams_only_in_players) > 0:\n",
    "        warnings.append(f\"{len(teams_only_in_players)} teams in player data but not games\")\n",
    "        print(f\"   ‚ö†Ô∏è  {len(teams_only_in_players)} teams in players but not games\")\n",
    "    \n",
    "    if len(teams_only_in_games) == 0 and len(teams_only_in_players) == 0:\n",
    "        print(f\"   ‚úÖ Team IDs match across dataframes\")\n",
    "    \n",
    "    return {\n",
    "        'issues': issues,\n",
    "        'warnings': warnings,\n",
    "        'passed': len(issues) == 0\n",
    "    }\n",
    "\n",
    "\n",
    "def validate_all(df_g, df_p):\n",
    "    \"\"\"\n",
    "    Run all validation checks\n",
    "    \n",
    "    Args:\n",
    "        df_g: Games DataFrame\n",
    "        df_p: Players DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        dict: Complete validation results\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"üîç \"*30)\n",
    "    print(\"STARTING COMPLETE DATA VALIDATION\")\n",
    "    print(\"üîç \"*30)\n",
    "    \n",
    "    # Run all validations\n",
    "    games_results = validate_games_dataframe(df_g)\n",
    "    players_results = validate_players_dataframe(df_p)\n",
    "    consistency_results = validate_consistency(df_g, df_p)\n",
    "    \n",
    "    # Combine results\n",
    "    all_issues = (games_results['issues'] + \n",
    "                  players_results['issues'] + \n",
    "                  consistency_results['issues'])\n",
    "    \n",
    "    all_warnings = (games_results['warnings'] + \n",
    "                    players_results['warnings'] + \n",
    "                    consistency_results['warnings'])\n",
    "    \n",
    "    # Final report\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìã VALIDATION SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if len(all_issues) == 0:\n",
    "        print(\"‚úÖ NO CRITICAL ISSUES FOUND\")\n",
    "    else:\n",
    "        print(f\"‚ùå {len(all_issues)} CRITICAL ISSUES FOUND:\")\n",
    "        for i, issue in enumerate(all_issues, 1):\n",
    "            print(f\"   {i}. {issue}\")\n",
    "    \n",
    "    if len(all_warnings) > 0:\n",
    "        print(f\"\\n‚ö†Ô∏è  {len(all_warnings)} WARNINGS:\")\n",
    "        for i, warning in enumerate(all_warnings, 1):\n",
    "            print(f\"   {i}. {warning}\")\n",
    "    else:\n",
    "        print(\"\\n‚úÖ NO WARNINGS\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    \n",
    "    if len(all_issues) == 0 and len(all_warnings) == 0:\n",
    "        print(\"üéâ DATA IS READY FOR MODELING!\")\n",
    "    elif len(all_issues) == 0:\n",
    "        print(\"‚úÖ DATA IS USABLE (with minor warnings)\")\n",
    "    else:\n",
    "        print(\"‚ùå FIX CRITICAL ISSUES BEFORE PROCEEDING\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return {\n",
    "        'games': games_results,\n",
    "        'players': players_results,\n",
    "        'consistency': consistency_results,\n",
    "        'all_issues': all_issues,\n",
    "        'all_warnings': all_warnings,\n",
    "        'passed': len(all_issues) == 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "427b0c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç üîç üîç üîç üîç üîç üîç üîç üîç üîç üîç üîç üîç üîç üîç üîç üîç üîç üîç üîç üîç üîç üîç üîç üîç üîç üîç üîç üîç üîç \n",
      "STARTING COMPLETE DATA VALIDATION\n",
      "üîç üîç üîç üîç üîç üîç üîç üîç üîç üîç üîç üîç üîç üîç üîç üîç üîç üîç üîç üîç üîç üîç üîç üîç üîç üîç üîç üîç üîç üîç \n",
      "\n",
      "============================================================\n",
      "üîç VALIDATING GAMES DATAFRAME\n",
      "============================================================\n",
      "\n",
      "üìä Dataset Info:\n",
      "   Total games: 7054\n",
      "   Date range: 2019-10-22 to 2025-04-13\n",
      "   Unique teams: 30\n",
      "\n",
      "üîç Checking for missing values...\n",
      "   ‚úÖ No missing values in critical columns\n",
      "\n",
      "üîç Checking for duplicates...\n",
      "   ‚úÖ No duplicate games\n",
      "\n",
      "üîç Checking chronological order...\n",
      "   ‚úÖ Games in chronological order\n",
      "\n",
      "üîç Checking score ranges...\n",
      "   Home scores: 73 to 175\n",
      "   Away scores: 67 to 176\n",
      "   ‚úÖ Score ranges look reasonable (50-200)\n",
      "\n",
      "üîç Checking data types...\n",
      "   ‚ö†Ô∏è  'date' is not datetime\n",
      "   üí° Fix: df_g['date'] = pd.to_datetime(df_g['date'])\n",
      "\n",
      "üîç Checking season distribution...\n",
      "   Games per season:\n",
      "      22019: 1059 games\n",
      "      22020: 1080 games\n",
      "      22021: 1230 games\n",
      "      22022: 1230 games\n",
      "      22023: 1230 games\n",
      "      22024: 1225 games\n",
      "\n",
      "üîç Checking team matchups...\n",
      "   ‚úÖ No games where team plays itself\n",
      "\n",
      "============================================================\n",
      "üîç VALIDATING PLAYERS DATAFRAME\n",
      "============================================================\n",
      "\n",
      "üìä Dataset Info:\n",
      "   Total records: 150087\n",
      "   Date range: 2019-10-22T00:00:00 to 2025-04-13T00:00:00\n",
      "   Unique players: 1068\n",
      "   Unique games: 7059\n",
      "\n",
      "üîç Checking for missing values...\n",
      "   ‚úÖ No missing values in critical columns\n",
      "\n",
      "üîç Checking for duplicates...\n",
      "   ‚úÖ No duplicate player-game records\n",
      "\n",
      "üîç Checking minutes played...\n",
      "   Minutes range: 0.0 to 56.516666666666666\n",
      "   Players with 0 minutes: 11\n",
      "   Players with <1 minute: 1362\n",
      "   ‚úÖ Most players have meaningful minutes\n",
      "\n",
      "üîç Checking stats consistency...\n",
      "   ‚úÖ FGM <= FGA for all records\n",
      "   ‚úÖ FG3M <= FG3A for all records\n",
      "   ‚úÖ FTM <= FTA for all records\n",
      "   ‚úÖ FG3M <= FGM for all records\n",
      "\n",
      "üîç Checking for negative values...\n",
      "   ‚úÖ No negative values in stats\n",
      "\n",
      "üîç Checking chronological order...\n",
      "   ‚úÖ Data in chronological order\n",
      "\n",
      "üîç Checking data types...\n",
      "   ‚ö†Ô∏è  'game_date' is not datetime\n",
      "   üí° Fix: df_p['game_date'] = pd.to_datetime(df_p['game_date'])\n",
      "\n",
      "============================================================\n",
      "üîç VALIDATING CROSS-DATAFRAME CONSISTENCY\n",
      "============================================================\n",
      "\n",
      "üîç Checking date ranges...\n",
      "   Games:   2019-10-22 to 2025-04-13\n",
      "   Players: 2019-10-22T00:00:00 to 2025-04-13T00:00:00\n",
      "   ‚ö†Ô∏è  Player data starts later than games\n",
      "\n",
      "üîç Checking game_id consistency...\n",
      "   Games with player data: 7054 / 7054\n",
      "   ‚ö†Ô∏è  5 orphan games in player data\n",
      "\n",
      "üîç Checking score consistency (sample of 10 games)...\n",
      "   ‚úÖ Player points sum to team totals\n",
      "\n",
      "üîç Checking team IDs...\n",
      "   ‚ö†Ô∏è  30 teams in games but not players\n",
      "   ‚ö†Ô∏è  30 teams in players but not games\n",
      "\n",
      "============================================================\n",
      "üìã VALIDATION SUMMARY\n",
      "============================================================\n",
      "‚úÖ NO CRITICAL ISSUES FOUND\n",
      "\n",
      "‚ö†Ô∏è  6 WARNINGS:\n",
      "   1. 'date' is not datetime type\n",
      "   2. 'game_date' is not datetime type\n",
      "   3. Player data starts later than games (2019-10-22T00:00:00 vs 2019-10-22)\n",
      "   4. 5 games in player data not in games data\n",
      "   5. 30 teams in games but not in player data\n",
      "   6. 30 teams in player data but not games\n",
      "\n",
      "============================================================\n",
      "‚úÖ DATA IS USABLE (with minor warnings)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "results = validate_all(df_g, df_p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
