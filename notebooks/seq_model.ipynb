{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c28ef0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src')))\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e1a386b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from data import ApiFetcher, DataPreparation\n",
    "from model.gru_team_embbedings import EmbeddingsTrain\n",
    "from model.gru_team_embbedings import TeamEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "52cc2d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      game_id  home_fga  away_fga  home_fg_pct  away_fg_pct  home_fg3a  \\\n",
      "0  0021900001       103       102        0.408        0.422         40   \n",
      "1  0021900002        81        85        0.519        0.435         31   \n",
      "2  0021900005        86        88        0.430        0.375         30   \n",
      "3  0021900009        76        93        0.461        0.398         36   \n",
      "4  0021900003        88       105        0.511        0.467         44   \n",
      "\n",
      "   away_fg3a  home_fg3_pct  away_fg3_pct  home_oreb  ...  away_blk  home_tov  \\\n",
      "0         45         0.350         0.422         16  ...         9        17   \n",
      "1         33         0.355         0.394         11  ...         7        14   \n",
      "2         34         0.300         0.265          7  ...         2        13   \n",
      "3         41         0.306         0.268          5  ...         3        20   \n",
      "4         30         0.523         0.300          9  ...         4        19   \n",
      "\n",
      "   away_tov  home_pf  away_pf  home_pts  away_pts  home_team_id  away_team_id  \\\n",
      "0        19       24       34       130       122            27            18   \n",
      "1        15       25       24       112       102            12            13   \n",
      "2        16       18       15        94        85            21             5   \n",
      "3        17       22       32       108       100             6            29   \n",
      "4        12       18       20       126       125             3             4   \n",
      "\n",
      "         date  \n",
      "0  2019-10-22  \n",
      "1  2019-10-22  \n",
      "2  2019-10-23  \n",
      "3  2019-10-23  \n",
      "4  2019-10-23  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "api = ApiFetcher(starting_year=2019, ending_year=2025)\n",
    "print(api.get_dataframe('leaguegamelog').head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c44cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPrepeparation = DataPreparation('leaguegamelog', starting_year=2000, ending_year=2025)\n",
    "train_ds, val_ds, test_ds = dataPrepeparation.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8d0857f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 17]) torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "x, home_ids, away_ids, y = train_ds[0]\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b0a980c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "n_teams = int(max(np.max(train_ds.home_ids), np.max(train_ds.away_ids)) + 1)\n",
    "print(n_teams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c9f378",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1f83430",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TeamEmbeddings(\n",
    "    input_num_features=x.shape[1],\n",
    "    n_teams=n_teams,\n",
    "    emb_dim=32,\n",
    "    hidden_size=128,\n",
    "    num_layers=3,\n",
    "    output_size=2,\n",
    ")\n",
    "trainer = EmbeddingsTrain(\n",
    "    model,\n",
    "    learning_rate=1e-3,\n",
    "    weight_decay=1e-4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1fe9d237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Średni loss na train_ds: 17.021\n",
      "VAL MAE: 10.356, VAL RMSE: 12.878\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# inicjalizacja trenera\n",
    "trainer = EmbeddingsTrain(model, learning_rate=1e-3)\n",
    "\n",
    "# online learning - batch_size = 1\n",
    "train_loader = DataLoader(train_ds, batch_size=1, shuffle=False)  # zachowujemy chronologię\n",
    "val_loader = DataLoader(val_ds, batch_size=1, shuffle=False)\n",
    "test_loader = DataLoader(test_ds, batch_size=1, shuffle=False)\n",
    "\n",
    "# ------------------------\n",
    "# TRAINING (online)\n",
    "# ------------------------\n",
    "train_losses = []\n",
    "for batch in train_loader:\n",
    "    loss = trainer.step(batch)\n",
    "    train_losses.append(loss)\n",
    "\n",
    "print(f\"Średni loss na train_ds: {sum(train_losses)/len(train_losses):.3f}\")\n",
    "\n",
    "# ------------------------\n",
    "# VALIDATION / TEST\n",
    "# ------------------------\n",
    "def evaluate(loader):\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "    for batch in loader:\n",
    "        preds = trainer.predict(batch)\n",
    "        if len(batch) == 2:\n",
    "            _, yb = batch\n",
    "        else:\n",
    "            _, _, _, yb = batch\n",
    "        targets_list.append(yb)\n",
    "        preds_list.append(preds)\n",
    "    return torch.cat(preds_list), torch.cat(targets_list)\n",
    "\n",
    "val_preds, val_targets = evaluate(val_loader)\n",
    "test_preds, test_targets = evaluate(test_loader)\n",
    "\n",
    "# przykładowe metryki\n",
    "mae = torch.mean(torch.abs(val_preds - val_targets.float()))\n",
    "rmse = torch.sqrt(torch.mean((val_preds - val_targets.float())**2))\n",
    "print(f\"VAL MAE: {mae:.3f}, VAL RMSE: {rmse:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d16a7919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 9.803990972457406\n",
      "Test MAE: 10.288990082572596\n",
      "Test RMSE: 12.874862479097734\n",
      "R² per target: [-0.025451064109802246, -0.004592180252075195]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "criterion = torch.nn.HuberLoss(reduction=\"sum\")\n",
    "l1 = torch.nn.L1Loss(reduction=\"sum\")\n",
    "mse = torch.nn.MSELoss(reduction=\"sum\")\n",
    "\n",
    "device = next(trainer.model.parameters()).device\n",
    "test_loader = DataLoader(test_ds, batch_size=1, shuffle=False, drop_last=False)\n",
    "\n",
    "trainer.model.eval()\n",
    "device = next(trainer.model.parameters()).device\n",
    "\n",
    "ss_res = torch.zeros(2, device=device)\n",
    "ss_tot = torch.zeros(2, device=device)\n",
    "y_tot_sum = torch.zeros(2, device=device)\n",
    "y_count = 0\n",
    "\n",
    "# najpierw sumujemy wartości, żeby policzyć mean\n",
    "for batch in test_loader:\n",
    "    if len(batch) == 2:\n",
    "        _, yb = batch\n",
    "    else:\n",
    "        _, _, _, yb = batch\n",
    "    yb = yb.to(device)\n",
    "    if yb.ndim == 3:\n",
    "        yb = yb.squeeze(1)\n",
    "    y_tot_sum += torch.sum(yb, dim=0)\n",
    "    y_count += yb.size(0)\n",
    "\n",
    "y_mean = y_tot_sum / y_count\n",
    "\n",
    "# teraz jeden przebieg: ss_res i ss_tot\n",
    "sum_loss = sum_mae = sum_mse = n = 0\n",
    "for batch in test_loader:\n",
    "    if len(batch) == 2:\n",
    "        xb, yb = batch\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "    else:\n",
    "        xb, home_ids, away_ids, yb = batch\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        home_ids, away_ids = home_ids.to(device), away_ids.to(device)\n",
    "\n",
    "    if yb.ndim == 3:\n",
    "        yb = yb.squeeze(1)\n",
    "\n",
    "    preds = trainer.model(xb) if len(batch) == 2 else trainer.model(xb, home_ids, away_ids)\n",
    "    \n",
    "    bs = yb.size(0)\n",
    "    sum_loss += criterion(preds, yb).item() * bs\n",
    "    sum_mae  += l1(preds, yb).item()\n",
    "    sum_mse  += mse(preds, yb).item()\n",
    "    \n",
    "    ss_res += torch.sum((yb - preds)**2, dim=0)\n",
    "    ss_tot += torch.sum((yb - y_mean)**2, dim=0)\n",
    "    n += bs * yb.shape[1]\n",
    "\n",
    "r2 = 1 - ss_res / ss_tot\n",
    "test_loss = sum_loss / n\n",
    "test_mae  = sum_mae / n\n",
    "test_rmse = (sum_mse / n) ** 0.5\n",
    "\n",
    "print(\"Test loss:\", test_loss)\n",
    "print(\"Test MAE:\", test_mae)\n",
    "print(\"Test RMSE:\", test_rmse)\n",
    "print(\"R² per target:\", r2.tolist())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
